# 上机报告
# 一、上机题目

## 1.1 题目要求

利用Apache netty构建爬虫服务器，爬取一定数目的网页，将抓取的网页中的文本内容发送给客户端，客户端将数据存储到Apache kafka消息队列或redis数据库中。

## 1.2 题目分析

根据题目要求可知，完成该题目需要在Linux环境进行，部署Apache Kafka、Apache Zookeeper、Apache Netty以及Redis。

![jiagou.png](https://img03.sogoucdn.com/app/a/100520146/e3864d1aab470c419f1d0d6326d93604)

由上图可知，Netty构建的crawler sever服务器有两项功能，一是服务器中有多个爬虫爬取Internet上的网页信息并提取网页文本和url信息，二是监听客户端的连接状态并将网页信息传输至客户端。

客户端的功能是将从服务端获取的信息发送到消息队列或redis数据库中。

可以写测试类，从Kafka消息队列中取出消息，以及从redis中取出信息。

# 二、环境配置

**初始环境**：ubuntu18.04 LTS Desktop Edition+orcale JDK8/openJDK8

**IDE**：Jetbrains IntelliJ IDEA Ultimate Edition 2019.03

**项目管理工具**：maven

## 2.1 Zookeeper配置

由于Kafka是一个分布式的消息队列，依赖Zookeeper对分布式的系统的管理。Zookeeper 作为一个分布式的服务框架，主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储，但是 Zookeeper 并不是用来专门存储数据的，它的作用主要是用来维护和监控你存储的数据的状态变化。

可以在Zookeeper的[官网](http://zookeeper.apache.org/releases.html)下载最新版本的Zookeeper。获取到 Zookeeper 的压缩包并解压到某个目录如：/home/zookeeper-3.5.6 下，Zookeeper 的启动脚本在 bin 目录下，Linux 下的启动脚本是 zkServer.sh。

Zookeeper 的配置文件在 conf 目录下，这个目录下有 zoo_sample.cfg 和 log4j.properties，你需要做的就是将 zoo_sample.cfg 改名为 zoo.cfg，因为 Zookeeper 在启动时会找这个文件作为默认配置文件。

![UTOOLS1575191759506.png](https://img02.sogoucdn.com/app/a/100520146/163366f25861e78c34064054de793f96)

<center>zoo.cfg配置</center>
- tickTime：这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。
- dataDir：顾名思义就是 Zookeeper 保存数据的目录，默认情况下，Zookeeper 将写数据的日志文件也保存在这个目录里。
- clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。

当这些配置项配置好后，你现在就可以启动 Zookeeper 了，启动后要检查 Zookeeper 是否已经在服务，可以通过 netstat – ano 命令查看是否有你配置的 clientPort 端口号在监听服务。

![UTOOLS1575189248370.png](https://img03.sogoucdn.com/app/a/100520146/6e287b8aab626b88d2824871d4aec3ad)

<center>Zookeeper的启动与停止</center>
## 2.2 Kafka配置

Kafka是一个分布式流处理系统，流处理系统使它可以像消息队列一样publish或者subscribe消息，分布式提供了容错性，并发处理消息的机制。

Kafka专为分布式高吞吐量系统而设计。 Kafka往往工作得很好，作为一个更传统的消息代理的替代品。 与其他消息传递系统相比，Kafka具有更好的吞吐量，内置分区，复制和固有的容错能力，这使得它非常适合大规模消息处理应用程序。

![UTOOLS1575190174217.png](https://img04.sogoucdn.com/app/a/100520146/db4d8cce2ed7564a33c4ab97f04ac570)

<center>Kafka原理图</center>
kafka属于发布订阅模型。发布订阅模型则是一个基于推送的消息传送模型。发布订阅模型可以有多种不同的订阅者，临时订阅者只在主动监听主题时才接收消息，而持久订阅者则监听主题的所有消息，即使当前订阅者不可用，处于离线状态。

Kafka 对消息保存时根据 Topic 进行归类，发送消息者称为 Producer，消息接受者称为 Consumer，此外 kafka 集群有多个 kafka 实例组成，每个实例(server)成为 broker。在单机环境下，不需要考虑broker的问题。

但是，无论是 kafka 集群，还是 producer 和 consumer 都依赖于 zookeeper 集群保存一些meta 信息，来保证系统可用性。

从kafka的[官网](http://kafka.apache.org/)获取最新版本的[kafka](https://www.apache.org/dyn/closer.cgi?path=/kafka/2.3.1/kafka_2.12-2.3.1.tgz)进行解压,kafka的二进制包中已经包含了默认配置的zookeeper。kafka启动过程如下：

```bash
#切换到kafka目录下
$ cd kafka_xxxx
#启动zookeeper
$ bin/zookeeper-server-start.sh config/zookeeper.properties
#启动kafka
$ bin/kafka-server-start.sh config/server.properties
```

## 2.3 Redis配置

Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。

它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Hash), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。

redis在linux环境下，安装十分简单，执行以下命令：

```bash
#更新所有依赖
$sudo apt-get update
#安装redis-server
$sudo apt-get install redis-server
```

# 三、模块设计

## 3.1 爬虫模块

netty原生仅支持http协议，若需支持https协议必须添加ssl证书。使用netty原生HttpRequest写爬虫服务不可行。因此，采用Apache Httpcomponents下的子模块**Httpclient**对网页进行抓取，使用**jsoup**对抓取的网页进行细致分析或利用**正则表达式**对网页进行简要的处理，例如获取文本信息。

由于大多数网站都设置了反爬机制，我们需要模拟浏览器的浏览行为进行抓取。因此，需要设置代理甚至设置cookies信息，代理和cookies信息可从浏览器中获得。

![UTOOLS1575194260732.png](https://img01.sogoucdn.com/app/a/100520146/18257406af03c516ae3a463b11bf46d2)

<center>User-Agent信息</center>
![UTOOLS1575194451475.png](https://img03.sogoucdn.com/app/a/100520146/a21172b5d20f7a8d03ec7c48caa2c35c)

<center>cookies信息</center>
对于同一个站点，如果我们短时间内大量访问，服务器很大的可能判断为Dos攻击，拒绝我们继续访问。可以设置合理的时间间隔进行访问或采用IP代理服务器，使用多个IP爬取网页。

crawler关键代码：

```java
        //create HttpClient
        CloseableHttpClient httpClient = HttpClients.createDefault();
        //create request
        HttpGet httpGet = new HttpGet(url);
        httpGet.setHeader("User-Agent","Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.87 Safari/537.36");
        //send request & receive response
        CloseableHttpResponse response = httpClient.execute(httpGet);
        //judge the status code
        if (response.getStatusLine().getStatusCode() == 200) {
            if (response.getEntity() != null) {
                return EntityUtils.toString(response.getEntity(), "UTF-8");
            }
        }
        return null;
```

在获取网页文本时，使用正则表达式。关键的正则表达式如下：

```java
// 定义script的正则表达式{或<script[^>]*?>[\\s\\S]*?<\\/script>
String regEx_script = "<[\\s]*?script[^>]*?>[\\s\\S]*?<[\\s]*?/[\\s]*?script[\\s]*?>"; 
 // 定义style的正则表达式{或<style[^>]*?>[\\s\\S]*?<\\/style>
String regEx_style = "<[\\s]*?style[^>]*?>[\\s\\S]*?<[\\s]*?/[\\s]*?style[\\s]*?>";
 // 定义HTML标签的正则表达式
String regEx_html = "<[^>]+>";
```

为了更好的鲁棒性，在爬虫多线程中使用线程池CachedThreadPool，避免使用Thread.start()方法。

爬取的网站为en.people.cn（人民日报海外版），爬取2015年至今的主页信息，根据观察，主页URL的格式为：

> ```elm
> http://en.people.cn/review/yyyymmdd.html
> ```

例如：http://en.people.cn/review/20191101.html

由以上发现，借助GenDate类生成2015年至今的url，并写进url.txt中。

## 3.2 netty服务器/客户端模块

netty服务器需要两个事件线程池，其中一个线程池负责监听客户端的请求，另一个线程池负责接受数据和发送数据。

netty服务器的启动需要两个步骤：

- netty服务器的设置

在netty服务器的设置中可以设置传输方式是异步还是同步，tcp buffer size和receive buffer size以及设置解码器、编码器和其他事件监听器。

- netty服务器的绑定、监听

netty服务器处理数据的过程由SeverHandler类决定，自定义的函数继承自ChannelInboundHandlerAdapter类，需要实现channelRead和exceptionCaught两个函数。

netty服务器主要代码：

```java
    void service() {
        //deal with connect
        EventLoopGroup poolGroup = new NioEventLoopGroup();
        //deal with transmission
        EventLoopGroup transmitGroup = new NioEventLoopGroup();
        //Bootstrap
        ServerBootstrap bootstrap = new ServerBootstrap();
        bootstrap.group(poolGroup, transmitGroup)
                /*channel type*/
                .channel(NioServerSocketChannel.class)
                //tcp buf size
                .option(ChannelOption.SO_BACKLOG, 1024)
                //receivebuf size
                .option(ChannelOption.SO_RCVBUF, 32 * 1024)
                .childHandler(new ChannelInitializer<SocketChannel>() {
                    @Override
                    protected void initChannel(SocketChannel socketChannel) {
                        socketChannel.pipeline().addLast(new StringDecoder());
                        socketChannel.pipeline().addLast(new ServerHandler(responses));
                    }
                });
        //bind port
        ChannelFuture channelFuture;
        try {
            channelFuture = bootstrap.bind(8765).sync();
            channelFuture.channel().closeFuture().sync();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        poolGroup.shutdownGracefully();
        transmitGroup.shutdownGracefully();
    }
```

netty的客户端仅需要一个线程池用来接受数据和发送数据。客户端的设置与服务器端的设置类似，主要区别在于:

- server使用childHandler函数而client使用handler函数。
- server使用bootstrap.bind().sync()绑定port,client使用bootstrap.connect().sync()发起连接请求。

## 3.4 kafka Producer/Consumer模块

利用kafka提供了KafkaProducer和KafkaConsumer两个Java API,向kafka写入数据或读取数据。

KafkaProducer API的中心部分是 KafkaProducer 类。 KafkaProducer类提供了一个选项，用于将其构造函数中的Kafka代理连接到以下方法。

KafkaProducer需要先进行配置，再进行数据的发送。

| 配置项           | 含义                                                         |
| ---------------- | ------------------------------------------------------------ |
| client.id        | 标识生产者应用程序                                           |
| producer.type    | 同步或异步                                                   |
| acks             | acks配置控制生产者请求下的标准是完全的                       |
| callback         | 如果生产者请求失败，则使用特定值自动重试                     |
| bootstrapping    | 代理列表                                                     |
| linger.ms        | 如果你想减少请求的数量，你可以将linger.ms设置为大于某个值的东西 |
| key.serializer   | 序列化器接口的键                                             |
| value.serializer | 值                                                           |
| batch.size       | 缓冲区大小                                                   |
| buffer.size      | 控制生产者可用于缓冲的存储器的总量                           |

KafkaConsumer的配置类似，不再赘述。

KafkaProducer主要代码：

```java
MyKafkaProducer(String topicName){
        //properties kafka producer
        Properties props = new Properties();
        ////bootstrapping proxy list.connect to port.Default port is 9092.
        props.put("bootstrap.servers", "localhost:9092");
        //
        props.put("acks", "all");
        //retry
        props.put("retries", 0);
        //buffer size
        props.put("batch.size", 16384);
        props.put("key.serializer", StringSerializer.class.getName());
        props.put("value.serializer", StringSerializer.class.getName());
        this.producer = new KafkaProducer<String, String>(props);
        //config topic
        this.topic = topicName;
    }
```



## 3.6 Redis Write/Read模块

redis单机单线程的读写较为简单。

Redis的Java API为Jedis,Write/Read的步骤为：

- 连接redis服务
- 写数据或读数据

# 四、性能测试

## 4.1 爬虫性能测试

对爬虫进行性能测试，分别爬取50、100、500、1000、2000个网页，使用1、2、5、10、15个线程，花费时间如下表所示：

|      |  1  |   2    |   5    |  10   |  15   |
| ---- | :-----: | :----: | :----: | :---: | :---: |
| 50   |  9.563  | 1.214  | 1.315  | 0.779 | 1.482 |
| 100  | 23.813  | 2.167  | 1.346  | 1.141 | 2.452 |
| 500  | 56.186  | 10.322 | 4.518  | 3.232 | 4.416 |
| 1000 | &infin; | 26.113 | 13.628 | 6.244 | 3.848 |
| 2000 | &infin; | 40.412 | 25.91  | 7.841 | 7.354 |

<center>性能测试表</center>
![图片2.png](https://img04.sogoucdn.com/app/a/100520146/807a03d6910028084f6dcbc9f466b652)

**分析：**

- 当url数一定时,随线程数增加,所花费时间迅速降低,但降低的速度减缓

- 当url=50/100/500时,线程数为15时所花费的时间高于线程数为10时，这是由于粒度过细，导致线程的开销花费时间高于线程工作的时间。



# 五、部分运行结果截取

<img src="https://img01.sogoucdn.com/app/a/100520146/e4e2aa44003ca85a0b8f4e0edb2ebdde" alt="UTOOLS1575223001170.png" style="zoom:80%;" />

<img src="https://img01.sogoucdn.com/app/a/100520146/d4e6a90eecd9f4fcc9890173fc39f023" alt="UTOOLS1575222962037.png" style="zoom:80%;" />

![UTOOLS1575217993076.png](https://img02.sogoucdn.com/app/a/100520146/851b6aeb3d30fabc2dce0a4c7e729978)

![UTOOLS1575219189317.png](https://img01.sogoucdn.com/app/a/100520146/375b59cc181d77580e840859c4803cd5)

![UTOOLS1575223270798.png](https://img01.sogoucdn.com/app/a/100520146/fa3d96f2c1d3801cdbfd7b16d2c6c390)

![UTOOLS1575223159901.png](https://img04.sogoucdn.com/app/a/100520146/c9fedad17067cd7369e665b824c90793)

